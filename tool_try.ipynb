{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ee81b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in h:\\conda\\lib\\site-packages (2.1.3)\n",
      "Collecting langchain\n",
      "  Downloading langchain-1.1.3-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting langchain-core<2.0.0,>=1.1.2 (from langchain)\n",
      "  Downloading langchain_core-1.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting langgraph<1.1.0,>=1.0.2 (from langchain)\n",
      "  Downloading langgraph-1.0.4-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in h:\\conda\\lib\\site-packages (from langchain) (2.10.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in h:\\conda\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (1.33)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.1.2->langchain)\n",
      "  Downloading langsmith-0.4.58-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in h:\\conda\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in h:\\conda\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in h:\\conda\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in h:\\conda\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.2->langchain) (4.12.2)\n",
      "Collecting uuid-utils<1.0,>=0.12.0 (from langchain-core<2.0.0,>=1.1.2->langchain)\n",
      "  Downloading uuid_utils-0.12.0-cp39-abi3-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in h:\\conda\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.2->langchain) (2.1)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading langgraph_sdk-0.2.15-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading xxhash-3.6.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading ormsgpack-1.12.0-cp313-cp313-win_amd64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in h:\\conda\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain)\n",
      "  Downloading orjson-3.11.5-cp313-cp313-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in h:\\conda\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in h:\\conda\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (2.32.3)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in h:\\conda\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in h:\\conda\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.7.0)\n",
      "Requirement already satisfied: certifi in h:\\conda\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in h:\\conda\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in h:\\conda\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in h:\\conda\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in h:\\conda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in h:\\conda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in h:\\conda\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in h:\\conda\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in h:\\conda\\lib\\site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.0)\n",
      "Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "Downloading langchain-1.1.3-py3-none-any.whl (102 kB)\n",
      "Downloading langchain_core-1.1.3-py3-none-any.whl (475 kB)\n",
      "Downloading langgraph-1.0.4-py3-none-any.whl (157 kB)\n",
      "Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
      "Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl (35 kB)\n",
      "Downloading langgraph_sdk-0.2.15-py3-none-any.whl (66 kB)\n",
      "Downloading langsmith-0.4.58-py3-none-any.whl (412 kB)\n",
      "Downloading uuid_utils-0.12.0-cp39-abi3-win_amd64.whl (183 kB)\n",
      "Downloading orjson-3.11.5-cp313-cp313-win_amd64.whl (133 kB)\n",
      "Downloading ormsgpack-1.12.0-cp313-cp313-win_amd64.whl (112 kB)\n",
      "Downloading xxhash-3.6.0-cp313-cp313-win_amd64.whl (31 kB)\n",
      "Installing collected packages: xxhash, uuid-utils, ormsgpack, orjson, opencv-python, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain\n",
      "\n",
      "   ------ ---------------------------------  2/12 [ormsgpack]\n",
      "   ------------- --------------------------  4/12 [opencv-python]\n",
      "   ------------- --------------------------  4/12 [opencv-python]\n",
      "   ------------- --------------------------  4/12 [opencv-python]\n",
      "   ------------- --------------------------  4/12 [opencv-python]\n",
      "   ------------- --------------------------  4/12 [opencv-python]\n",
      "   ------------- --------------------------  4/12 [opencv-python]\n",
      "   ------------- --------------------------  4/12 [opencv-python]\n",
      "   ------------- --------------------------  4/12 [opencv-python]\n",
      "   ------------- --------------------------  4/12 [opencv-python]\n",
      "   ------------- --------------------------  4/12 [opencv-python]\n",
      "   ------------- --------------------------  4/12 [opencv-python]\n",
      "   ------------- --------------------------  4/12 [opencv-python]\n",
      "   ---------------- -----------------------  5/12 [langsmith]\n",
      "   ---------------- -----------------------  5/12 [langsmith]\n",
      "   ---------------- -----------------------  5/12 [langsmith]\n",
      "   ---------------- -----------------------  5/12 [langsmith]\n",
      "   ---------------- -----------------------  5/12 [langsmith]\n",
      "   ---------------- -----------------------  5/12 [langsmith]\n",
      "   ---------------- -----------------------  5/12 [langsmith]\n",
      "   ---------------- -----------------------  5/12 [langsmith]\n",
      "   ---------------- -----------------------  5/12 [langsmith]\n",
      "   ---------------- -----------------------  5/12 [langsmith]\n",
      "   ---------------- -----------------------  5/12 [langsmith]\n",
      "   ---------------- -----------------------  5/12 [langsmith]\n",
      "   ---------------- -----------------------  5/12 [langsmith]\n",
      "   ---------------- -----------------------  5/12 [langsmith]\n",
      "   ---------------- -----------------------  5/12 [langsmith]\n",
      "   ---------------- -----------------------  5/12 [langsmith]\n",
      "   ---------------- -----------------------  5/12 [langsmith]\n",
      "   -------------------- -------------------  6/12 [langgraph-sdk]\n",
      "   -------------------- -------------------  6/12 [langgraph-sdk]\n",
      "   -------------------- -------------------  6/12 [langgraph-sdk]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   ----------------------- ----------------  7/12 [langchain-core]\n",
      "   -------------------------- -------------  8/12 [langgraph-checkpoint]\n",
      "   -------------------------- -------------  8/12 [langgraph-checkpoint]\n",
      "   -------------------------- -------------  8/12 [langgraph-checkpoint]\n",
      "   -------------------------- -------------  8/12 [langgraph-checkpoint]\n",
      "   ------------------------------ ---------  9/12 [langgraph-prebuilt]\n",
      "   --------------------------------- ------ 10/12 [langgraph]\n",
      "   --------------------------------- ------ 10/12 [langgraph]\n",
      "   --------------------------------- ------ 10/12 [langgraph]\n",
      "   --------------------------------- ------ 10/12 [langgraph]\n",
      "   --------------------------------- ------ 10/12 [langgraph]\n",
      "   --------------------------------- ------ 10/12 [langgraph]\n",
      "   --------------------------------- ------ 10/12 [langgraph]\n",
      "   --------------------------------- ------ 10/12 [langgraph]\n",
      "   --------------------------------- ------ 10/12 [langgraph]\n",
      "   --------------------------------- ------ 10/12 [langgraph]\n",
      "   --------------------------------- ------ 10/12 [langgraph]\n",
      "   --------------------------------- ------ 10/12 [langgraph]\n",
      "   --------------------------------- ------ 10/12 [langgraph]\n",
      "   --------------------------------- ------ 10/12 [langgraph]\n",
      "   ------------------------------------ --- 11/12 [langchain]\n",
      "   ------------------------------------ --- 11/12 [langchain]\n",
      "   ------------------------------------ --- 11/12 [langchain]\n",
      "   ------------------------------------ --- 11/12 [langchain]\n",
      "   ------------------------------------ --- 11/12 [langchain]\n",
      "   ------------------------------------ --- 11/12 [langchain]\n",
      "   ------------------------------------ --- 11/12 [langchain]\n",
      "   ---------------------------------------- 12/12 [langchain]\n",
      "\n",
      "Successfully installed langchain-1.1.3 langchain-core-1.1.3 langgraph-1.0.4 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.5 langgraph-sdk-0.2.15 langsmith-0.4.58 opencv-python-4.12.0.88 orjson-3.11.5 ormsgpack-1.12.0 uuid-utils-0.12.0 xxhash-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python numpy langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3bdd2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-1.1.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.1 in h:\\conda\\lib\\site-packages (from langchain-openai) (1.1.3)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in h:\\conda\\lib\\site-packages (from langchain-openai) (2.9.0)\n",
      "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai)\n",
      "  Downloading tiktoken-0.12.0-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in h:\\conda\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.1->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in h:\\conda\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.1->langchain-openai) (0.4.58)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in h:\\conda\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.1->langchain-openai) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in h:\\conda\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.1->langchain-openai) (2.10.3)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in h:\\conda\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.1->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in h:\\conda\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.1->langchain-openai) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in h:\\conda\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.1->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in h:\\conda\\lib\\site-packages (from langchain-core<2.0.0,>=1.1.1->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in h:\\conda\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.1->langchain-openai) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in h:\\conda\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.1->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in h:\\conda\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.1->langchain-openai) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in h:\\conda\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.1->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in h:\\conda\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.1->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in h:\\conda\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.1->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: anyio in h:\\conda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.1->langchain-openai) (4.7.0)\n",
      "Requirement already satisfied: certifi in h:\\conda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.1->langchain-openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in h:\\conda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.1->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: idna in h:\\conda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.1->langchain-openai) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in h:\\conda\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.1->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in h:\\conda\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in h:\\conda\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in h:\\conda\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in h:\\conda\\lib\\site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in h:\\conda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.1.1->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in h:\\conda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.1.1->langchain-openai) (2.27.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in h:\\conda\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in h:\\conda\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.1->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in h:\\conda\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.1->langchain-openai) (2.3.0)\n",
      "Requirement already satisfied: colorama in h:\\conda\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.109.1->langchain-openai) (0.4.6)\n",
      "Downloading langchain_openai-1.1.1-py3-none-any.whl (84 kB)\n",
      "Downloading tiktoken-0.12.0-cp313-cp313-win_amd64.whl (879 kB)\n",
      "   ---------------------------------------- 0.0/879.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 879.1/879.1 kB 19.1 MB/s eta 0:00:00\n",
      "Installing collected packages: tiktoken, langchain-openai\n",
      "\n",
      "   ---------------------------------------- 0/2 [tiktoken]\n",
      "   ---------------------------------------- 0/2 [tiktoken]\n",
      "   -------------------- ------------------- 1/2 [langchain-openai]\n",
      "   -------------------- ------------------- 1/2 [langchain-openai]\n",
      "   -------------------- ------------------- 1/2 [langchain-openai]\n",
      "   -------------------- ------------------- 1/2 [langchain-openai]\n",
      "   ---------------------------------------- 2/2 [langchain-openai]\n",
      "\n",
      "Successfully installed langchain-openai-1.1.1 tiktoken-0.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30618087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import operator\n",
    "from typing import Annotated, List, TypedDict\n",
    "from collections import Counter\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3870608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain.tools import tool\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph.message import add_messages  # <--- CRITICAL IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55228cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"Check your .env file for OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6f95ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def check_dominant_colors(image_path: str):\n",
    "    \"\"\"\n",
    "    Analyzes the image to find the top 3 dominant colors in Hex format.\n",
    "    Use this when a rule requires checking specific colors (e.g. #FF0000).\n",
    "    Returns: List of hex strings like ['#ff0000', '#ffffff'].\n",
    "    \"\"\"\n",
    "    print(f\"\\n   [TOOL ACTIVITY] ðŸ› ï¸  Opening image: {image_path}...\")\n",
    "    \n",
    "    if not os.path.exists(image_path):\n",
    "        return \"Error: Image file not found.\"\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None: \n",
    "        return \"Error: Could not read image.\"\n",
    "\n",
    "    # Convert BGR to RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Fast color extraction\n",
    "    pixels = image.reshape(-1, 3)\n",
    "    counts = Counter(map(tuple, pixels[::10])) \n",
    "    top_3 = counts.most_common(3)\n",
    "    \n",
    "    hex_colors = []\n",
    "    for color, count in top_3:\n",
    "        hex_str = '#{:02x}{:02x}{:02x}'.format(*color)\n",
    "        hex_colors.append(hex_str)\n",
    "        \n",
    "    print(f\"   [TOOL ACTIVITY] ðŸ”  Found Colors: {hex_colors}\\n\")\n",
    "    return hex_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4ea85e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "# Initialize the LLM with the Tool\n",
    "tools = [check_dominant_colors]\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(tools)\n",
    "\n",
    "# Node 1: The Brain\n",
    "def call_model(state: AgentState):\n",
    "    messages = state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    # We return a list, and LangGraph will append it to the existing state\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Node 2: The Tool Runner\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# The Workflow Graph\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Conditional Edge\n",
    "def should_continue(state: AgentState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "workflow.add_conditional_edges(\"agent\", should_continue)\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04b6f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_compliance_check(image_path, json_rules_path):\n",
    "    # Ensure dummy rule file exists if not provided\n",
    "    if not os.path.exists(json_rules_path):\n",
    "        print(f\"Creating dummy {json_rules_path}...\")\n",
    "        with open(json_rules_path, \"w\") as f:\n",
    "            f.write(\"\"\"{\"rules\": [{\"rule_id\": \"test\", \"description\": \"Ball must be red\", \"parameters\": {\"hex\": \"#FF0000\"}}]}\"\"\")\n",
    "\n",
    "    with open(json_rules_path, \"r\") as f:\n",
    "        rules = f.read()\n",
    "\n",
    "    print(f\"--- ðŸš€ STARTING TEST ON {image_path} ---\")\n",
    "    \n",
    "    initial_message = HumanMessage(\n",
    "        content=f\"\"\"\n",
    "        You are a Compliance Officer. \n",
    "        1. Read these rules: {rules}\n",
    "        2. Check this image: '{image_path}'\n",
    "        3. VERIFY if the image follows the color rule. \n",
    "        4. YOU MUST USE THE TOOL to see the colors. Do not guess.\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    inputs = {\"messages\": [initial_message]}\n",
    "\n",
    "    try:\n",
    "        for event in app.stream(inputs):\n",
    "            for key, value in event.items():\n",
    "                if key == \"agent\":\n",
    "                    msg = value[\"messages\"][0]\n",
    "                    print(\"ðŸ¤– [AGENT THOUGHT]:\")\n",
    "                    if msg.tool_calls:\n",
    "                        print(f\"    I need to check the color. Calling tool: {msg.tool_calls[0]['name']}\")\n",
    "                    else:\n",
    "                        print(f\"    Final Answer: {msg.content}\")\n",
    "                elif key == \"tools\":\n",
    "                    print(\"âš¡ [TOOL RESULT]:\")\n",
    "                    # In the new State, 'value' might contain the message update\n",
    "                    # We just print confirmation here\n",
    "                    print(f\"    Tool returned data to the Agent.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ ERROR: {e}\")\n",
    "        print(\"Tip: Make sure you have the 'langgraph' and 'langchain-openai' libraries updated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c82fb443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ðŸš€ STARTING TEST ON ball.jpeg ---\n",
      "ðŸ¤– [AGENT THOUGHT]:\n",
      "    I need to check the color. Calling tool: check_dominant_colors\n",
      "\n",
      "   [TOOL ACTIVITY] ðŸ› ï¸  Opening image: ball.jpeg...\n",
      "   [TOOL ACTIVITY] ðŸ”  Found Colors: ['#ffffff', '#fffeff', '#813a40']\n",
      "\n",
      "âš¡ [TOOL RESULT]:\n",
      "    Tool returned data to the Agent.\n",
      "ðŸ¤– [AGENT THOUGHT]:\n",
      "    Final Answer: The dominant colors detected in the image 'ball.jpeg' are:\n",
      "\n",
      "1. #ffffff (White)\n",
      "2. #fffeff (Almost White)\n",
      "3. #813a40 (A shade of red, possibly maroon or crimson)\n",
      "\n",
      "To verify compliance with the rule, we need to check if the primary object (ball) is semantically red. The color #813a40 appears to be a shade of red, which aligns with the rule's requirement for the ball to be semantically red, including shades like crimson or maroon.\n",
      "\n",
      "Therefore, the image complies with the \"ball_color_check\" rule, as the detected color #813a40 is recognized as a shade of red.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Ensure you have a 'ball.jpeg' (or png) in the folder\n",
    "    # If not, create a dummy file or use a real path\n",
    "    if not os.path.exists(\"ball.jpeg\"):\n",
    "         print(\"âš ï¸  Warning: 'ball.jpeg' not found. Please put a red image in this folder named 'ball.jpeg'.\")\n",
    "    else:\n",
    "         run_compliance_check(\"ball.jpeg\", \"test_rules.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
